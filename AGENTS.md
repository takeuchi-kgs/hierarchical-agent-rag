# Google Agent Development Kit (ADK) Python Snippets

## 0. まとめて import

```python
from typing import Optional, AsyncGenerator

from google.adk.agents import (
    LlmAgent,
    SequentialAgent,
    LoopAgent,
    BaseAgent,
)
from google.adk.agents.callback_context import CallbackContext
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

from google.adk.tools import FunctionTool
from google.adk.tools.agent_tool import AgentTool
from google.adk.tools.tool_context import ToolContext

from google.adk.models import LlmRequest, LlmResponse
from google.genai import types
```

---

## 1. FunctionTool / AgentTool

### 1-1. FunctionTool で Python 関数をツール化

```python
# シンプルな Python 関数
def get_current_time(tool_context: ToolContext) -> str:
    """現在時刻を返すツール（例なので適当でOK）"""
    import datetime as dt

    now = dt.datetime.utcnow().isoformat()
    # state に書き込んで後続エージェントで参照もできる
    tool_context.state["last_time_called"] = now
    return now

# FunctionTool でラップ
get_current_time_tool = FunctionTool(func=get_current_time)
```

※ ADK は「素の関数を tools=[fn] に渡す」だけでもよしなにラップしてくれますが、
`ToolContext` を使いたいなら `FunctionTool` 明示のほうがわかりやすい。

```python
async def call_ds_agent(
    question: str,
    tool_context: ToolContext,
):
    """
    Tool to call the data science (nl2py) agent.

    After the ds_agent runs and potentially generates a graph, this tool
    extracts the graph file from the agent's output and saves it as an artifact.
    """

    if question == "N/A":
        return tool_context.state["db_agent_output"]

    # The result of the SQL query is expected to be in the state.
    input_data = tool_context.state.get("query_result", "")

    question_with_data = f"""
  Question to answer: {question}

  The data to analyze, which resulted from a previous SQL query, is as follows:
  {input_data}

  """

    agent_tool = AgentTool(agent=ds_agent)

    ds_agent_output = await agent_tool.run_async(
        args={"request": question_with_data}, tool_context=tool_context
    )
    tool_context.state["ds_agent_output"] = ds_agent_output

    # --- Artifact Saving Logic for Graph ---
    # The ds_agent with a CodeExecutor returns an AgentToolOutput object.
    # The `files` attribute contains any files generated by the code execution.
    if hasattr(ds_agent_output, 'files') and ds_agent_output.files:
        for file in ds_agent_output.files:
            # Assuming the first image file is the graph we want to save.
            if file.mime_type.startswith("image/"):
                graph_file_name = "analysis_graph.png"
                await tool_context.save_artifact(filename=graph_file_name, artifact=file)
                print(f"Successfully saved graph to artifact: {graph_file_name}")
                # Stop after saving the first graph.
                break

    return ds_agent_output
```

---

### 1-2. AgentTool でエージェントをツールとして使う

```python
# サブエージェント（検索エージェントなど）の定義
search_agent = LlmAgent(
    name="SearchAgent",
    model="gemini-2.5-pro",
    description="検索用エージェント",
    instruction="ユーザーの質問に答えるために、必要なら google_search ツールを使って検索してください。",
    tools=[...],  # 例えば google_search など
)

# AgentTool でラップ
search_agent_tool = AgentTool(agent=search_agent)

# ルートエージェントから見ると「ツールの一つ」として見える
root_agent = LlmAgent(
    name="RootAgent",
    model="gemini-2.5-pro",
    description="マネージャーエージェント",
    instruction="必要に応じて SearchAgent ツールを呼び出して、ユーザーにとって最適な回答を返してください。",
    tools=[
        search_agent_tool,
        get_current_time_tool,
    ],
)
```

---

## 2. コールバック 4種（モデル & エージェント）

### 2-1. before_model_callback / after_model_callback

```python
# LLM 呼び出し前: プロンプト書き換え / ガードレール / キャッシュなど
def before_model_guardrail(
    callback_context: CallbackContext,
    llm_request: LlmRequest,
) -> Optional[LlmResponse]:
    """
    ・llm_request を読んでブロック条件をチェック
    ・ブロックしたいなら LlmResponse を返す
    ・通常は None を返して LLM 呼び出しを続行
    """
    last = llm_request.contents[-1] if llm_request.contents else None
    if last and last.parts and "禁止ワード" in (last.parts[0].text or ""):
        # LLM を呼ばずに即レス
        return LlmResponse(
            content=types.Content(
                role="model",
                parts=[types.Part(text="その質問には回答できません。")],
            )
        )
    return None


# LLM 応答後: ログ / 再フォーマット / ポストプロセス
def after_model_logger(
    callback_context: CallbackContext,
    llm_response: LlmResponse,
) -> Optional[LlmResponse]:
    """
    ・llm_response を読んで書き換えたいときは新しい LlmResponse を返す
    ・触るだけ（ログだけ）なら None を返す
    """
    agent_name = callback_context.agent_name
    print(f"[after_model] {agent_name} -> {llm_response}")

    # ここではそのまま通す
    return None
```

---

### 2-2. before_agent_callback / after_agent_callback

```python
# エージェント実行前: state を見て実行をスキップしたりできる
def before_agent_callback(
    callback_context: CallbackContext,
) -> Optional[types.Content]:
    """
    ・callback_context.state を見て、このエージェントをスキップするか判断
    ・スキップしたいなら Content を返す
    ・通常は None を返してエージェントを実行
    """
    if callback_context.state.get("skip_llm_agent"):
        return types.Content(
            role="model",
            parts=[types.Part(text="このエージェントは state によりスキップされました。")],
        )
    return None


# エージェント実行後: 後処理 / 追記など
def after_agent_callback(
    callback_context: CallbackContext,
) -> Optional[types.Content]:
    """
    ・直前のエージェント出力を差し替えたいなら Content を返す
    ・ログだけなら None を返す
    """
    agent_name = callback_context.agent_name
    print(f"[after_agent] finished: {agent_name}")
    return None
```

---

## 3. LlmAgent / SequentialAgent / LoopAgent / ParallelAgent

### 3-1. LlmAgent にツール & コールバックを全部盛り

```python
llm_agent = LlmAgent(
    name="MainLlmAgent",
    model="gemini-2.5-pro",
    description="ツールとコールバックを試すサンプル LlmAgent",
    instruction="ユーザーの質問に答えつつ、必要ならツールを使ってください。",
    tools=[get_current_time_tool],
    output_key="output_key"
    output_schema=OutputSchema,
    # Agent ライフサイクル
    before_agent_callback=before_agent_callback,
    after_agent_callback=after_agent_callback,
    # モデル I/O
    before_model_callback=before_model_guardrail,
    after_model_callback=after_model_logger,
)
```

---

### 3-2. SequentialAgent（順次実行）

```python
# サブエージェントをいくつか定義
step1_agent = LlmAgent(
    name="Step1",
    model="gemini-2.5-pro",
    description="前処理担当",
    instruction="ユーザーの要求を整理し、タスク分解してください。",
)

step2_agent = LlmAgent(
    name="Step2",
    model="gemini-2.5-pro",
    description="最終回答担当",
    instruction="Step1 の出力を踏まえて、最終回答を作成してください。",
)

pipeline_agent = SequentialAgent(
    name="PipelineAgent",
    description="2 ステップの順次パイプライン",
    sub_agents=[step1_agent, step2_agent],
    # 必要ならここにも before/after_agent_callback を付与できる
)
```

---

### 3-3. LoopAgent（条件付きループ）

```python
# 例: 「ドラフト作成」→「レビュー」を max 5 回まで繰り返す
draft_agent = LlmAgent(
    name="DraftAgent",
    model="gemini-2.5-pro",
    description="ドラフト生成",
    instruction="与えられたテーマでドラフトを 1 つ作ってください。",
)

review_agent = LlmAgent(
    name="ReviewAgent",
    model="gemini-2.5-pro",
    description="レビュー & 合否判定",
    instruction=(
        "ドラフトをレビューして、十分なら 'APPROVED'、"
        "要改善なら 'REVISE' とコメントを添えて返してください。"
    ),
)

loop_agent = LoopAgent(
    name="DraftReviewLoop",
    description="ドラフトとレビューのループ",
    sub_agents=[draft_agent, review_agent],
    max_iterations=5,  # 任意。条件だけで抜けるなら省略も可
)
```

※ 実際にループを抜けるには、`Event.actions.escalate=True` を使うか、
ドキュメントのパターンに従って「終了条件を満たしたらエスカレートするサブエージェント」を用意する。

---

### 3-4. ParallelAgent

```python
# --- Step 1: それぞれ独立に処理するエージェント ---
step1_agent = LlmAgent(
    name="Step1",
    model="gemini-2.5-pro",
    description="ユーザー要求の整理とタスク分解",
    instruction="ユーザー要求を整理し、タスクを分解してください。",
    output_key="step1_result"
)

step2_agent = LlmAgent(
    name="Step2",
    model="gemini-2.5-pro",
    description="別観点での追加分析",
    instruction="ユーザー要求を別観点から分析してください。",
    output_key="step2_result"
)

# --- Step 2: 並列実行 ---
parallel_agent = ParallelAgent(
    name="ParallelAnalysis",
    description="2つの分析エージェントを並列実行する",
    sub_agents=[step1_agent, step2_agent],
)
```

---

## 4. CustomAgent（BaseAgent 継承）

非 LLM ロジックや細かい制御を入れたいとき用。

```python
class CounterAgent(BaseAgent):
    name: str = "CounterAgent"
    description: str = "state['count'] をインクリメントして返すカスタムエージェント"

    async def _run_async_impl(
        self,
        context: InvocationContext,
    ) -> AsyncGenerator[Event, None]:
        # state はセッション共有
        count = context.state.get("count", 0)
        count += 1
        context.state["count"] = count

        content = types.Content(
            role="model",
            parts=[types.Part(text=f"現在のカウント: {count}")],
        )

        # 少なくとも 1 つは Event を yield する必要がある
        yield Event(
            author=self.name,
            content=content,
        )
```

`CustomAgent` も他のエージェントと同様に `SequentialAgent` / `LoopAgent` の `sub_agents` に混ぜて使える。

---

## 5. Runner で実行する

### 5-1. InMemorySessionService + Runner

```python
import asyncio

app_name = "sample_adk_app"
user_id = "user_1"
session_id = "session_1"

# セッションサービス（ローカル検証用）
session_service = InMemorySessionService()

# ここで使うエージェントを選ぶ（llm_agent / pipeline_agent / loop_agent / custom など）
root_agent = pipeline_agent  # 例

runner = Runner(
    agent=root_agent,
    app_name=app_name,
    session_service=session_service,
    # 必要なら memory_service などもここで渡す
)

# セッション作成
runner.session_service.create_session(
    app_name=app_name,
    user_id=user_id,
    session_id=session_id,
)


async def run_once(query: str) -> str:
    user_content = types.Content(
        role="user",
        parts=[types.Part(text=query)],
    )

    events = []
    async for event in runner.run_async(
        user_id=user_id,
        session_id=session_id,
        new_message=user_content,
    ):
        if event:
            events.append(event)

    # 一番最後の Event から text だけ取り出す簡易版
    last = events[-1]
    content = last.content
    text = ""
    if content and content.parts and content.parts[0].text:
        text = content.parts[0].text
    return text


if __name__ == "__main__":
    print(asyncio.run(run_once("テスト用のプロンプトです。")))
```

---

## 6. state 書き込みパターン

### 6-1. LlmAgent の `output_key` で state に書く

```python
from google.adk.agents import LlmAgent, SequentialAgent

summarizer = LlmAgent(
    name="Summarizer",
    model="gemini-2.5-pro",
    description="テキストを要約するエージェント",
    instruction="ユーザーの入力を3文以内で要約してください。",
    output_key="summary_text",       # ← ここに書き込まれる
)

qa_maker = LlmAgent(
    name="QAMaker",
    model="gemini-2.5-pro",
    description="要約を基に質問を生成するエージェント",
    instruction=(
        "session.state['summary_text'] を読み、"
        "理解度を測る質問を3つ生成してください。"
    ),
)

pipeline = SequentialAgent(
    name="SummaryPipeline",
    description="要約 → QA 生成パイプライン",
    sub_agents=[summarizer, qa_maker],
)
```

- **ポイント**
  - `summarizer` の出力は自動で `session.state["summary_text"]` に保存され、
  後続エージェントが参照可能になる。

---

### 6-2. ツールから state に直接書く

```python
from google.adk.tools.tool_context import ToolContext

def remember_user_pref(key: str, value: str, tool_context: ToolContext) -> dict:
    """
    ユーザーの設定・好みなどを state に永続化するツール
    """
    state_key = f"user:pref:{key}"
    tool_context.state[state_key] = value

    return {
        "status": "success",
        "saved_key": state_key,
        "saved_value": value,
    }

def get_user_pref(key: str, tool_context: ToolContext) -> dict:
    """
    上記で保存した値を読み出すツール
    """
    state_key = f"user:pref:{key}"
    value = tool_context.state.get(state_key)

    if value is None:
        return {"status": "not_found"}

    return {"status": "success", "value": value}
```

```python
from google.adk.tools import FunctionTool
from google.adk.agents import LlmAgent

remember_tool = FunctionTool(func=remember_user_pref)
get_tool = FunctionTool(func=get_user_pref)

profile_agent = LlmAgent(
    name="ProfileAgent",
    model="gemini-2.5-pro",
    description="ユーザーの好みを保存・活用するエージェント",
    instruction="ユーザーの設定を聞き、remember/get のツールを使用して state に保存・参照せよ。",
    tools=[remember_tool, get_tool],
)
```

- **ポイント**
  - 長期的に必要な情報 → `user:` プレフィックス
  - セッション単位でよい → プレフィックスなしの `state["foo"]` でOK

---

## 7. LoopAgent + EscalationChecker パターン

### 7-1. 評価結果を state に書くエージェント

```python
from google.adk.agents import LlmAgent

eval_agent = LlmAgent(
    name="EvalAgent",
    model="gemini-2.5-pro",
    description="ドラフトの評価担当",
    instruction=(
        "draft_text を評価せよ。十分なら grade='pass'、"
        "不十分なら grade='fail' と理由を返すこと。\n"
        "必ず JSON: {\"grade\": ..., \"reason\": ...} 形式で返すこと。"
    ),
    output_key="evaluation_result",   # JSON文字列がここに格納される
)
```

---

### 7-2. EscalationChecker（CustomAgent）

ループの継続/終了を制御する

```python
import json
from typing import AsyncGenerator
from google.adk.agents import BaseAgent
from google.adk.agents.invocation_context import InvocationContext
from google.adk.events import Event, EventActions

class EscalationChecker(BaseAgent):
    name: str = "EscalationChecker"
    description: str = "evaluation_result を見てループ終了を判断"

    async def _run_async_impl(
        self, context: InvocationContext
    ) -> AsyncGenerator[Event, None]:
        raw = context.state.get("evaluation_result", "{}")

        try:
            evaluation = json.loads(raw) if isinstance(raw, str) else raw
        except:
            evaluation = {}

        grade = evaluation.get("grade")

        if grade == "pass":
            # ループ脱出
            yield Event(author=self.name, actions=EventActions(escalate=True))
        else:
            # 継続
            yield Event(author=self.name)
```

---

### 7-3. LoopAgent にまとめる

```python
draft_agent = LlmAgent(
    name="DraftAgent",
    model="gemini-2.5-pro",
    description="ドラフト生成",
    instruction=(
        "topic と過去の評価を考慮して draft_text を生成せよ。"
    ),
    output_key="draft_text",
)

from google.adk.agents import LoopAgent

refine_loop = LoopAgent(
    name="DraftRefineLoop",
    description="ドラフト生成 → 評価 → 合格まで繰り返し",
    sub_agents=[
        draft_agent,
        eval_agent,
        EscalationChecker(),
    ],
    max_iterations=5,
)
```

**なぜこの構造が重要か？**

- ループ終了ロジックを LLM プロンプトに埋め込むと、
  **不定形で壊れやすい・テストできない** 混沌になる。
- `EscalationChecker` に切り出すと、
  **“どこでループが決まるか”がコードで固定される** → 再現性・テスト容易。

---

## 8. Evaluation & テスト

### 8-1. evalset JSON（最小構成）

`tests/myapp.evalset.json`

```jsonc
{
  "eval_set_id": "myapp_eval",
  "eval_cases": [
    {
      "eval_id": "tokyo_time",
      "conversation": [
        {
          "user_content": {
            "parts": [{ "text": "東京の現在時刻は？" }]
          },
          "final_response": {
            "parts": [{ "text": "東京" }],
            "match_type": "contains"
          },
          "intermediate_data": {
            "tool_uses": [
              {
                "name": "get_current_time",
                "args": { "city": "Tokyo" }
              }
            ]
          }
        }
      ],
      "session_input": {
        "app_name": "my_app",
        "user_id": "eval_user",
        "state": {}
      }
    }
  ]
}
```

---

### 8-2. CLIで評価

```bash
adk eval my_app tests/myapp.evalset.json
```

---

### 8-3. pytest と AgentEvaluator で自動テスト

```python
# tests/test_eval.py
from google.adk.testing import AgentEvaluator

def test_myapp_eval():
    evaluator = AgentEvaluator(
        agent_path="my_app",
        evalset_path="tests/myapp.evalset.json",
    )

    results = evaluator.evaluate()

    assert results.response_match_score >= 0.7

    for eval_id, case in results.cases.items():
        assert case.passed, f"Eval failed: {eval_id} / {case.error}"
```

- CI に載せると「ツール呼び順が壊れた」「ループが終わらない」などを自動検出できる
- 特に LoopAgent と相性が良い（繰り返し数・評価条件が壊れるとすぐ気付く）
